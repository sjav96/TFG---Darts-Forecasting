{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-HODkB3VWaF",
        "outputId": "a5297db5-d596-4ddf-bc25-f9459b904536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting darts\n",
            "  Downloading darts-0.26.0-py3-none-any.whl (784 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m784.8/784.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: holidays>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from darts) (0.34)\n",
            "Requirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from darts) (1.3.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from darts) (3.7.1)\n",
            "Collecting nfoursid>=1.0.0 (from darts)\n",
            "  Downloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from darts) (1.23.5)\n",
            "Collecting pmdarima>=1.8.0 (from darts)\n",
            "  Downloading pmdarima-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyod>=0.9.5 (from darts)\n",
            "  Downloading pyod-1.1.0.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from darts) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from darts) (1.11.3)\n",
            "Collecting shap>=0.40.0 (from darts)\n",
            "  Downloading shap-0.43.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting statsforecast>=1.4 (from darts)\n",
            "  Downloading statsforecast-1.6.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.9/110.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from darts) (0.14.0)\n",
            "Collecting tbats>=1.1.0 (from darts)\n",
            "  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.10/dist-packages (from darts) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from darts) (4.5.0)\n",
            "Requirement already satisfied: xarray>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2023.7.0)\n",
            "Requirement already satisfied: xgboost>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2.0.0)\n",
            "Collecting pytorch-lightning>=1.5.0 (from darts)\n",
            "  Downloading pytorch_lightning-2.1.0-py3-none-any.whl (774 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.6/774.6 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX>=2.1 (from darts)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2.0.1+cu118)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from darts) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from holidays>=0.11.1->darts) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (3.1.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->darts) (2023.3.post1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts) (3.0.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts) (2.0.6)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts) (67.7.2)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod>=0.9.5->darts) (0.56.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyod>=0.9.5->darts) (1.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.5.0->darts) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.5.0->darts) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.5.0->darts)\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities>=0.8.0 (from pytorch-lightning>=1.5.0->darts)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->darts) (3.2.0)\n",
            "Collecting slicer==0.0.7 (from shap>=0.40.0->darts)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap>=0.40.0->darts) (2.2.1)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (from statsforecast>=1.4->darts) (0.17.3)\n",
            "Collecting fugue>=0.8.1 (from statsforecast>=1.4->darts)\n",
            "  Downloading fugue-0.8.6-py3-none-any.whl (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.0/275.0 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.0->darts) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.1->darts) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->darts) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->darts) (17.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (3.8.6)\n",
            "Collecting triad>=0.9.1 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading triad-0.9.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading adagio-0.2.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pyarrow>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (9.0.0)\n",
            "Collecting qpd>=0.4.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading qpd-0.4.4-py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.2/169.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fugue-sql-antlr>=0.1.6 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading fugue-sql-antlr-0.1.7.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sqlglot (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading sqlglot-18.15.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.8/318.8 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.39.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->darts) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->darts) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5.0->darts) (1.3.1)\n",
            "Collecting antlr4-python3-runtime<4.12,>=4.11.1 (from fugue-sql-antlr>=0.1.6->fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fs (from triad>=0.9.1->fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs->triad>=0.9.1->fugue>=0.8.1->statsforecast>=1.4->darts) (1.4.4)\n",
            "Building wheels for collected packages: pyod, fugue-sql-antlr\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.1.0-py3-none-any.whl size=185329 sha256=fd71b65a8be63b90efc9ade47127a81e912f15561638fa3f90091af32ad93076\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/8e/e2/e932956b10b843eb6be9eefa70b5c1bee7b561be14c423b136\n",
            "  Building wheel for fugue-sql-antlr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fugue-sql-antlr: filename=fugue_sql_antlr-0.1.7-py3-none-any.whl size=158204 sha256=ef25dad180a46a293ae87c86e1d245a08eec27132f54cfa04fdcad8b9fef755a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/6a/bb/a1d60fffdfaeabda73de1364df4f6ad6586a052b07ec03e5af\n",
            "Successfully built pyod fugue-sql-antlr\n",
            "Installing collected packages: antlr4-python3-runtime, tensorboardX, sqlglot, slicer, lightning-utilities, fs, triad, shap, pyod, nfoursid, pmdarima, fugue-sql-antlr, adagio, tbats, qpd, fugue, statsforecast, torchmetrics, pytorch-lightning, darts\n",
            "Successfully installed adagio-0.2.4 antlr4-python3-runtime-4.11.1 darts-0.26.0 fs-2.4.16 fugue-0.8.6 fugue-sql-antlr-0.1.7 lightning-utilities-0.9.0 nfoursid-1.0.1 pmdarima-2.0.3 pyod-1.1.0 pytorch-lightning-2.1.0 qpd-0.4.4 shap-0.43.0 slicer-0.0.7 sqlglot-18.15.0 statsforecast-1.6.0 tbats-1.1.3 tensorboardX-2.6.2.2 torchmetrics-1.2.0 triad-0.9.1\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.21)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.12.0 colorlog-6.7.0 optuna-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install darts\n",
        "!pip install utils\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UwDK2s3VXzP"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X45cKQL0VZnM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from darts import TimeSeries\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\n",
        "from darts.metrics import mape\n",
        "from darts.utils.statistics import check_seasonality, plot_acf\n",
        "from darts.datasets import AirPassengersDataset, SunspotsDataset\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
        "\n",
        "import warnings\n",
        "import optuna\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import logging\n",
        "\n",
        "logging.disable(logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqZprbPfVckb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t__iJCWIVd9_"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Datasets/processed_dataset(3).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "data = data.set_index('Date')\n",
        "data.index = pd.to_datetime(data.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo6WyYPqVfaV"
      },
      "outputs": [],
      "source": [
        "split_date = pd.to_datetime('2020-12-31 23:59')\n",
        "data = data[data.index >= split_date]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_envKUBkVguG"
      },
      "outputs": [],
      "source": [
        "# data['Temperature t+24'] = data['Temperature'].shift(periods=-24)\n",
        "# data['Humidity t+24'] = data['Humidity'].shift(periods=-24-)\n",
        "data['Year'] = data.index.year\n",
        "# data['Year t+24'] = data['Year'].shift(periods=-24)\n",
        "data['Month'] = data.index.month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d_NCWQOVieq"
      },
      "outputs": [],
      "source": [
        "data_sin = data[['SIN']]\n",
        "data_cov = data[['Temperature', 'Humidity', 'Year', 'Month']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAnBXIuXVjs-"
      },
      "outputs": [],
      "source": [
        "series = TimeSeries.from_dataframe(data_sin, value_cols=[\"SIN\"])\n",
        "covariates = TimeSeries.from_dataframe(data_cov, value_cols=[\"Temperature\", \"Humidity\", \"Year\", \"Month\"])\n",
        "series = series.astype(np.float32)\n",
        "covariates = covariates.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsN7xvkabhuD"
      },
      "outputs": [],
      "source": [
        "# Time series plots for each column\n",
        "data.plot(subplots=True, layout=(5,1), figsize=(20, 12))\n",
        "plt.show()\n",
        "\n",
        "# Box plot for SIN by month to observe seasonality and outliers\n",
        "data.boxplot(column='SIN', by='Month')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPpvx-gfVlVz"
      },
      "outputs": [],
      "source": [
        "# # Create training and validation sets:\n",
        "training_cutoff = pd.Timestamp(\"20211231T230000\")\n",
        "train, val = series.split_after(training_cutoff)\n",
        "validation_cutoff = pd.Timestamp(\"20220131T230000\")\n",
        "val, not_used = val.split_after(validation_cutoff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hedRoDefVm85"
      },
      "outputs": [],
      "source": [
        "# Normalize the time series (note: we avoid fitting the transformer on the validation set)\n",
        "transformer = Scaler()\n",
        "train_transformed = transformer.fit_transform(train)\n",
        "val_transformed = transformer.transform(val)\n",
        "series_transformed = transformer.transform(series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh81V9HrVocb"
      },
      "outputs": [],
      "source": [
        "covariates = covariates.stack(\n",
        "    TimeSeries.from_times_and_values(\n",
        "        times=series.time_index,\n",
        "        values=np.arange(len(series)),\n",
        "        columns=[\"linear_increase\"],\n",
        "    )\n",
        ")\n",
        "covariates = covariates.astype(np.float32)\n",
        "cov_train, cov_val = covariates.split_after(training_cutoff)\n",
        "cov_val, not_used = cov_val.split_after(validation_cutoff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OlTwSLkVqMz"
      },
      "outputs": [],
      "source": [
        "# transform covariates (note: we fit the transformer on train split and can then transform the entire covariates series)\n",
        "scaler_covs = Scaler()\n",
        "covariates_transformed_train = scaler_covs.fit_transform(cov_train)\n",
        "covariates_transformed_val = scaler_covs.transform(cov_val)\n",
        "covariates_transformed = scaler_covs.transform(covariates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7CzzVLIftvX"
      },
      "outputs": [],
      "source": [
        "from darts.models import TFTModel, ARIMA, RNNModel\n",
        "\n",
        "# Train TFT\n",
        "# tft = TFTModel(input_chunk_length=365, output_chunk_length=24)\n",
        "tft = TFTModel(\n",
        "    input_chunk_length=336,\n",
        "    output_chunk_length=24,\n",
        "    hidden_size=64,\n",
        "    lstm_layers=1,\n",
        "    num_attention_heads=4,\n",
        "    dropout=0.1,\n",
        "    batch_size=16,\n",
        "    n_epochs=50,\n",
        "    add_relative_index=False,\n",
        "    add_encoders=None,\n",
        "    # loss_fn=MSELoss(),\n",
        "    random_state=42,\n",
        ")\n",
        "tft.fit(train_transformed, future_covariates=covariates_transformed, verbose=True)\n",
        "\n",
        "# Train ARIMA (it doesn't handle covariates)\n",
        "arima = ARIMA()\n",
        "arima.fit(train_transformed)\n",
        "\n",
        "# Train LSTM\n",
        "lstm = RNNModel(model='LSTM', input_chunk_length=336, output_chunk_length=24, n_epochs=50)\n",
        "lstm.fit(train_transformed, future_covariates=covariates_transformed_train, verbose=True)\n",
        "\n",
        "# Train GRU\n",
        "gru = RNNModel(model='GRU', input_chunk_length=336, output_chunk_length=24, n_epochs=50)\n",
        "gru.fit(train_transformed, future_covariates=covariates_transformed_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLsVu4RsNTYk"
      },
      "outputs": [],
      "source": [
        "# Predictions for 2022 (24 hours ahead)\n",
        "tft_pred = tft.predict(n=24, future_covariates=covariates_transformed)\n",
        "arima_pred = arima.predict(n=24)\n",
        "lstm_pred = lstm.predict(n=24, future_covariates=covariates_transformed)\n",
        "gru_pred = gru.predict(n=24, future_covariates=covariates_transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVcsbbkWNv3o"
      },
      "outputs": [],
      "source": [
        "tft_pred = transformer.inverse_transform(tft_pred)\n",
        "arima_pred = transformer.inverse_transform(arima_pred)\n",
        "lstm_pred = transformer.inverse_transform(lstm_pred)\n",
        "gru_pred = transformer.inverse_transform(gru_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHRIy6k2Nxah"
      },
      "outputs": [],
      "source": [
        "# Plotting model predictions\n",
        "plt.figure(figsize=(12, 8))\n",
        "val.plot(label='True', lw=2)\n",
        "tft_pred.plot(label='TFT Predictions', lw=2)\n",
        "arima_pred.plot(label='ARIMA Predictions', lw=2)\n",
        "lstm_pred.plot(label='LSTM Predictions', lw=2)\n",
        "gru_pred.plot(label='GRU Predictions', lw=2)\n",
        "plt.title(\"Predictions vs. Actual Values\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvDxuSGiP0Ws"
      },
      "outputs": [],
      "source": [
        "# Extracting the first 24 hours from actual and prediction data\n",
        "valid_24h = val[:24]\n",
        "tft_pred_24h = tft_pred[:24]\n",
        "arima_pred_24h = arima_pred[:24]\n",
        "lstm_pred_24h = lstm_pred[:24]\n",
        "gru_pred_24h = gru_pred[:24]\n",
        "\n",
        "# Plotting model predictions for the first 24 hours\n",
        "plt.figure(figsize=(12, 8))\n",
        "valid_24h.plot(label='True', lw=2)\n",
        "tft_pred_24h.plot(label='TFT Predictions', lw=2)\n",
        "arima_pred_24h.plot(label='ARIMA Predictions', lw=2)\n",
        "lstm_pred_24h.plot(label='LSTM Predictions', lw=2)\n",
        "gru_pred_24h.plot(label='GRU Predictions', lw=2)\n",
        "plt.title(\"Predictions vs. Actual Values for the First 24 Hours\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5N4VL6WOPCX"
      },
      "outputs": [],
      "source": [
        "from darts.metrics import mape, mae, rmse\n",
        "\n",
        "def compute_metrics(model_name, actual, predictions):\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'MAPE': mape(actual, predictions),\n",
        "        'MAE': mae(actual, predictions),\n",
        "        'RMSE': rmse(actual, predictions)\n",
        "    }\n",
        "\n",
        "metrics = pd.DataFrame([\n",
        "    compute_metrics('TFT', val, tft_pred),\n",
        "    compute_metrics('ARIMA', val, arima_pred),\n",
        "    compute_metrics('LSTM', val, lstm_pred),\n",
        "    compute_metrics('GRU', val, gru_pred)\n",
        "])\n",
        "\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vICZmUlt-yH4"
      },
      "outputs": [],
      "source": [
        "def compute_hppe(actual, predicted):\n",
        "    \"\"\"\n",
        "    Compute the Hourly Peak Percentage Error for each hour.\n",
        "\n",
        "    Parameters:\n",
        "    - actual: The actual values (TimeSeries object)\n",
        "    - predicted: The predicted values (TimeSeries object)\n",
        "\n",
        "    Returns:\n",
        "    - List of hourly percentage errors\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure that actual and predicted are of the same length\n",
        "    assert len(actual) == len(predicted), \"Both series must have the same length\"\n",
        "\n",
        "    hourly_percentage_errors = []\n",
        "\n",
        "    # Loop through each hour\n",
        "    for i in range(len(actual)):\n",
        "        actual_peak = actual[i].values()[0]\n",
        "        predicted_peak = predicted[i].values()[0]\n",
        "\n",
        "        # Compute the percentage error for the peak of the hour\n",
        "        percentage_error = abs((actual_peak - predicted_peak) / actual_peak) * 100\n",
        "        hourly_percentage_errors.append(percentage_error)\n",
        "\n",
        "    return hourly_percentage_errors\n",
        "\n",
        "# Computing HPPE for each model, assuming you have predictions for each\n",
        "hppe_gru = compute_hppe(valid_24h, gru_pred_24h)\n",
        "hppe_tft = compute_hppe(valid_24h, tft_pred_24h)\n",
        "hppe_arima = compute_hppe(valid_24h, arima_pred_24h)\n",
        "hppe_lstm = compute_hppe(valid_24h, lstm_pred_24h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-canDcLt-5KS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Plot histograms for each model\n",
        "plt.hist(hppe_gru, bins=20, alpha=0.5, label='GRU')\n",
        "plt.hist(hppe_tft, bins=20, alpha=0.5, label='TFT')\n",
        "plt.hist(hppe_arima, bins=20, alpha=0.5, label='ARIMA')\n",
        "plt.hist(hppe_lstm, bins=20, alpha=0.5, label='LSTM')\n",
        "\n",
        "# Set graph labels and title\n",
        "plt.xlabel('Percentage Error')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Hourly Peak Percentage Errors')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aL7u66qVyr5"
      },
      "outputs": [],
      "source": [
        "# import optuna\n",
        "# from darts.metrics import rmse\n",
        "# def objective(trial):\n",
        "#     # Hyperparameters to be tuned\n",
        "#     input_chunk_length = trial.suggest_int(\"input_chunk_length\", 100, 500, step=50)\n",
        "#     output_chunk_length = trial.suggest_int(\"output_chunk_length\", 12, 48, step=12)\n",
        "\n",
        "#     # Define and train the TFT model\n",
        "#     tft = TFTModel(input_chunk_length=input_chunk_length, output_chunk_length=output_chunk_length)\n",
        "#     tft.fit(train_transformed, future_covariates=covariates_transformed)\n",
        "\n",
        "#     # Predict and calculate RMSE\n",
        "#     tft_pred = tft.predict(n=24, future_covariates=covariates_transformed)\n",
        "#     tft_pred = transformer.inverse_transform(tft_pred)\n",
        "#     error = rmse(val[:24], tft_pred)\n",
        "\n",
        "#     return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvJxaeGlV_Yc"
      },
      "outputs": [],
      "source": [
        "# study = optuna.create_study(direction='minimize')  # We aim to minimize RMSE\n",
        "# study.optimize(objective, n_trials=10)  # number of trials can be adjusted based on computational capacity\n",
        "\n",
        "# best_params = study.best_params\n",
        "# print(f\"The best parameters are {best_params} with a RMSE of {study.best_value}.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}